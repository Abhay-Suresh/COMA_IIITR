{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72721022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and config\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats  # for Pearson correlation\n",
    "\n",
    "# API from your generator module; ensure knapsack_data_generator.py is in same folder or on PYTHONPATH\n",
    "from knapsack_data_generator import generate_batch\n",
    "\n",
    "# configure defaults\n",
    "OUT_ROOT = Path(\"knapsack_multisize_data\")\n",
    "OUT_ROOT.mkdir(exist_ok=True)\n",
    "SIZES = [50, 200, 500]          # change or extend as you like\n",
    "BASE_SEED = 20251018\n",
    "CAPACITY_RATIOS = [0.2, 0.5, 0.8]\n",
    "WEIGHT_RANGE = (1, 500)\n",
    "VALUE_RANGE = (1, 1000)\n",
    "FORCE_OVERWRITE = True            # set False to keep previously generated files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3748d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating instances for sizes: [50, 200, 500]\n",
      "Across capacity ratios: [0.2, 0.5, 0.8]\n",
      "Across weight distribution : ('normal', 'uniform', 'zipf')\n",
      "\n",
      "Generating 9 instance batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Batches: 100%|██████████| 9/9 [00:00<00:00, 147.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation complete. Metadata saved to knapsack_multisize_data\\generation_metadata.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# (Assuming imports, SIZES, CAPACITY_RATIOS, OUT_ROOT, etc., are defined)\n",
    "from tqdm import tqdm # <-- Import tqdm\n",
    "\n",
    "# Generate batches for uniform / normal / zipf\n",
    "meta = {} # This will now be nested: meta[dist_name][cap_ratio_name]\n",
    "\n",
    "print(f\"Generating instances for sizes: {SIZES}\")\n",
    "print(f\"Across capacity ratios: {CAPACITY_RATIOS}\")\n",
    "print(f\"Across weight distribution : {\"normal\", \"uniform\", \"zipf\"}\")\n",
    "\n",
    "dists = {\n",
    "    # Using larger offsets to ensure seed ranges are distinct\n",
    "    \"uniform\": {\"weight_dist\":\"uniform\", \"value_dist\":\"uniform\", \"seed_offset\": 0},\n",
    "    \"normal\":  {\"weight_dist\":\"normal\",  \"value_dist\":\"normal\",  \"seed_offset\": 100},\n",
    "    \"zipf\":    {\"weight_dist\":\"zipf\",    \"value_dist\":\"zipf\",    \"seed_offset\": 200}\n",
    "}\n",
    "\n",
    "# --- MODIFICATION: Create a flat list of all generation tasks ---\n",
    "tasks = []\n",
    "for dist_name, cfg in dists.items():\n",
    "    meta[dist_name] = {} # Pre-initialize sub-dictionary\n",
    "    for cap_ratio in CAPACITY_RATIOS:\n",
    "        tasks.append((dist_name, cfg, cap_ratio))\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# --- MODIFICATION: Loop over the flat task list with tqdm ---\n",
    "print(f\"\\nGenerating {len(tasks)} instance batches...\")\n",
    "\n",
    "for dist_name, cfg, cap_ratio in tqdm(tasks, desc=\"Generating Batches\"):\n",
    "    \n",
    "    # Create a safe directory name, e.g., \"cap_0.2\"\n",
    "    cap_name = f\"cap_{cap_ratio}\" \n",
    "    \n",
    "    # Create a nested output directory, e.g., knapsack_multisize_data/uniform/cap_0.2\n",
    "    out_dir = OUT_ROOT / dist_name / cap_name \n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # (Removed the print statement here, tqdm handles progress)\n",
    "\n",
    "    # Calculate a unique base seed for this combination\n",
    "    batch_base_seed = BASE_SEED + cfg[\"seed_offset\"] + int(cap_ratio * 10) \n",
    "\n",
    "    # Call generate_batch with the specific capacity_ratio and seed\n",
    "    # NOTE: The generate_batch function itself prints \"Saved: ...\"\n",
    "    # This will interleave with the progress bar, which is fine.\n",
    "    records = generate_batch(\n",
    "        ns=SIZES,\n",
    "        output_dir=str(out_dir),\n",
    "        weight_range=WEIGHT_RANGE,\n",
    "        value_range=VALUE_RANGE,\n",
    "        capacity_ratio=cap_ratio,  # Pass the current loop's ratio\n",
    "        correlation=None,\n",
    "        weight_dist=cfg[\"weight_dist\"],\n",
    "        value_dist=cfg[\"value_dist\"],\n",
    "        base_seed=batch_base_seed,   # Pass the new unique base seed\n",
    "        force_overwrite=FORCE_OVERWRITE\n",
    "    )\n",
    "    \n",
    "    # Store records in the nested meta dictionary\n",
    "    meta[dist_name][cap_name] = records\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# Save a small metadata summary\n",
    "meta_path = OUT_ROOT / \"generation_metadata.json\"\n",
    "with open(meta_path, \"w\", encoding=\"utf8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(f\"\\nGeneration complete. Metadata saved to {meta_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb730fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verification of Loaded Instances ---\n",
      "Size 50:\n",
      "  Dist 'uniform': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "  Dist 'normal': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "  Dist 'zipf': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "Size 200:\n",
      "  Dist 'uniform': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "  Dist 'normal': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "  Dist 'zipf': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "Size 500:\n",
      "  Dist 'uniform': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "  Dist 'normal': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "  Dist 'zipf': loaded ratios -> ['cap_0.2', 'cap_0.5', 'cap_0.8']\n",
      "\n",
      "--- Example Access ---\n",
      "Accessing: instances[50]['uniform']['cap_0.2']\n",
      "  -> Instance capacity: 2516\n",
      "  -> Instance items: 50\n",
      "  -> Instance meta seed: 20251020\n"
     ]
    }
   ],
   "source": [
    "# Helper to load an instance JSON given the record returned by generate_batch\n",
    "def load_instance_json(path):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        print(f\"Warning: File not found, skipping: {path}\")\n",
    "        return None\n",
    "    with path.open(\"r\", encoding=\"utf8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Build a mapping: mapping[size][dist][cap_ratio_name] -> instance dict\n",
    "# (This assumes SIZES, meta, and Path are defined from the previous script)\n",
    "\n",
    "# Initialize the 3-level nested dictionary\n",
    "instances = {n: {} for n in SIZES}\n",
    "for n in SIZES:\n",
    "    for dist_name in meta.keys(): # e.g., 'uniform', 'normal'\n",
    "        instances[n][dist_name] = {} # e.g., instances[50]['uniform'] = {}\n",
    "\n",
    "# --- Updated Loading Loop ---\n",
    "# We now have a 3-level loop to match the meta structure\n",
    "for dist_name, cap_dict in meta.items():\n",
    "    # cap_dict is {'cap_0.2': [...], 'cap_0.5': [...], ...}\n",
    "    for cap_name, records in cap_dict.items():\n",
    "        # records is the list of records for this config, e.g., [{'n': 50, ...}, {'n': 200, ...}]\n",
    "        for rec in records:\n",
    "            n = rec[\"n\"]\n",
    "            json_path = rec[\"json\"]\n",
    "            \n",
    "            inst = load_instance_json(json_path)\n",
    "            if inst:\n",
    "                # Store in the new 3-level structure\n",
    "                instances[n][dist_name][cap_name] = inst\n",
    "            \n",
    "# --- Updated Verification Print ---\n",
    "print(\"--- Verification of Loaded Instances ---\")\n",
    "for n in SIZES:\n",
    "    print(f\"Size {n}:\")\n",
    "    if not instances[n]:\n",
    "        print(\"  No data loaded.\")\n",
    "        continue\n",
    "        \n",
    "    for dist_name, cap_data in instances[n].items():\n",
    "        # This lists the capacity ratios loaded for this size and distribution\n",
    "        loaded_ratios = list(cap_data.keys()) \n",
    "        print(f\"  Dist '{dist_name}': loaded ratios -> {loaded_ratios}\")\n",
    "\n",
    "# Example of how to access a specific instance\n",
    "try:\n",
    "    first_size = SIZES[0]\n",
    "    first_dist = list(meta.keys())[0]\n",
    "    first_cap = list(meta[first_dist].keys())[0]\n",
    "    \n",
    "    example_instance = instances[first_size][first_dist][first_cap]\n",
    "    \n",
    "    print(\"\\n--- Example Access ---\")\n",
    "    print(f\"Accessing: instances[{first_size}]['{first_dist}']['{first_cap}']\")\n",
    "    print(f\"  -> Instance capacity: {example_instance['capacity']}\")\n",
    "    print(f\"  -> Instance items: {len(example_instance['items'])}\")\n",
    "    print(f\"  -> Instance meta seed: {example_instance['meta']['seed']}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not access example instance: {e}\")\n",
    "    print(\"Check if generation was successful and 'meta' object is populated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0731b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 9 distribution histogram plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Histograms: 100%|██████████| 9/9 [00:04<00:00,  1.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# (Assuming imports like plt, Path, SIZES, OUT_ROOT, and the 'instances' dict are loaded)\n",
    "from tqdm import tqdm  # <-- Import the tqdm library for progress bars\n",
    "\n",
    "# Plotting comparative histograms for each size\n",
    "SAVE_PLOTS = True\n",
    "# --- MODIFICATION: Define root plot dir and specific subdir ---\n",
    "PLOTS_ROOT = OUT_ROOT / \"plots\"\n",
    "PLOTS_DIR = PLOTS_ROOT / \"distributions\" # <-- New subdirectory name\n",
    "PLOTS_ROOT.mkdir(exist_ok=True)\n",
    "PLOTS_DIR.mkdir(exist_ok=True) # <-- Create the new subdirectory\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Define the order for columns\n",
    "dist_order = [\"uniform\", \"normal\", \"zipf\"]\n",
    "\n",
    "# --- MODIFICATION: Create a flat list of all plotting tasks ---\n",
    "# (This logic is unchanged)\n",
    "plot_tasks = []\n",
    "for n in SIZES:\n",
    "    # Find all capacity ratios loaded for this size\n",
    "    all_cap_ratios_for_n = set()\n",
    "    for dname in dist_order:\n",
    "        if n in instances and dname in instances[n]:\n",
    "            all_cap_ratios_for_n.update(instances[n][dname].keys())\n",
    "\n",
    "    if not all_cap_ratios_for_n:\n",
    "        print(f\"No data found for size {n}, skipping plot.\")\n",
    "        continue\n",
    "    \n",
    "    sorted_cap_ratios = sorted(list(all_cap_ratios_for_n))\n",
    "    \n",
    "    # Add a (size, cap_name) tuple for each plot to be generated\n",
    "    for cap_name in sorted_cap_ratios:\n",
    "        plot_tasks.append((n, cap_name))\n",
    "\n",
    "# --- MODIFICATION: Loop over the flat task list with tqdm ---\n",
    "if plot_tasks:\n",
    "    # --- MODIFICATION: Updated print statement ---\n",
    "    print(f\"Generating {len(plot_tasks)} distribution histogram plots...\")\n",
    "    \n",
    "    # Wrap the iterable 'plot_tasks' with tqdm() to create a progress bar\n",
    "    for n, cap_name in tqdm(plot_tasks, desc=\"Generating Histograms\"):\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 8), tight_layout=True)\n",
    "        \n",
    "        # determine reasonable bin counts\n",
    "        bins_w = 40 if n <= 500 else 80\n",
    "        bins_v = 40 if n <= 500 else 80\n",
    "        \n",
    "        capacity_str = \"capacity=N/A\" \n",
    "\n",
    "        # Loop over each distribution (columns)\n",
    "        for j, dname in enumerate(dist_order):\n",
    "            \n",
    "            # Access the nested instance\n",
    "            inst = instances[n].get(dname, {}).get(cap_name)\n",
    "            \n",
    "            if inst is None:\n",
    "                axes[0, j].text(0.5,0.5, f\"missing\\n{dname}/{cap_name}\", ha='center')\n",
    "                axes[1, j].text(0.5,0.5, f\"missing\\n{dname}/{cap_name}\", ha='center')\n",
    "                continue\n",
    "\n",
    "            if j == 0 or capacity_str == \"capacity=N/A\":\n",
    "                capacity_str = f\"capacity={inst['capacity']}\"\n",
    "\n",
    "            weights = [it[\"weight\"] for it in inst[\"items\"]]\n",
    "            values  = [it[\"value\"]  for it in inst[\"items\"]]\n",
    "\n",
    "            # Plot Weight\n",
    "            axes[0, j].hist(weights, bins=bins_w)\n",
    "            axes[0, j].set_title(f\"Weights — {dname.capitalize()}\")\n",
    "            axes[0, j].set_xlabel(\"weight\")\n",
    "            axes[0, j].set_ylabel(\"count\")\n",
    "            axes[0, j].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "            # Plot Value\n",
    "            axes[1, j].hist(values, bins=bins_v)\n",
    "            axes[1, j].set_title(f\"Values  — {dname.capitalize()}\")\n",
    "            axes[1, j].set_xlabel(\"value\")\n",
    "            axes[1, j].set_ylabel(\"count\")\n",
    "            axes[1, j].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        fig.suptitle(f\"Knapsack Item Distributions — n = {n}, {cap_name} ({capacity_str})\", fontsize=16)\n",
    "\n",
    "        if SAVE_PLOTS:\n",
    "            # --- MODIFICATION: Path now points to the 'distributions' subdir ---\n",
    "            out_path = PLOTS_DIR / f\"distributions_n{n}_{cap_name}.png\"\n",
    "            # ------------------------------------------------------------------\n",
    "            fig.savefig(out_path, bbox_inches=\"tight\", dpi=150)\n",
    "            # No print statement here, tqdm handles progress\n",
    "        plt.close(fig)\n",
    "            \n",
    "        # --- MODIFICATION: plt.show() is removed ---\n",
    "        \n",
    "        # Close the figure to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d979849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 9 summary visualization plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Viz Summaries: 100%|██████████| 9/9 [00:03<00:00,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All summary visualizations saved to knapsack_multisize_data\\plots\\summaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# (Assuming imports like plt, np, Path, SIZES, OUT_ROOT, and 'instances' are loaded)\n",
    "from tqdm import tqdm # For progress bar\n",
    "\n",
    "# --- MODIFICATION: Define root plot dir and specific subdir ---\n",
    "PLOTS_ROOT = OUT_ROOT / \"plots\"  # Assuming OUT_ROOT is defined\n",
    "SUMMARIES_DIR = PLOTS_ROOT / \"summaries\" # <-- New subdirectory name\n",
    "PLOTS_ROOT.mkdir(exist_ok=True)\n",
    "SUMMARIES_DIR.mkdir(exist_ok=True) # <-- Create the new subdirectory\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# --- Helper functions (from your script) ---\n",
    "# (Removed the mkdir line from here)\n",
    "def ecdf(data):\n",
    "    a = np.sort(np.asarray(data))\n",
    "    n = a.size\n",
    "    y = np.arange(1, n+1) / n\n",
    "    return a, y\n",
    "\n",
    "def ccdf(data):\n",
    "    a = np.sort(np.asarray(data))\n",
    "    n = a.size\n",
    "    y = 1.0 - (np.arange(0, n) / n)\n",
    "    return a, y\n",
    "# ------------------------------------------\n",
    "\n",
    "SAVE = True\n",
    "# Define order and colors for consistent plotting\n",
    "dist_order = [\"uniform\", \"normal\", \"zipf\"]\n",
    "colors = {\"uniform\":\"tab:blue\", \"normal\":\"tab:green\", \"zipf\":\"tab:orange\"}\n",
    "\n",
    "# --- Create a flat list of all plotting tasks ---\n",
    "# (This logic is unchanged)\n",
    "plot_tasks = []\n",
    "for n in sorted(instances.keys()):\n",
    "    all_cap_ratios_for_n = set()\n",
    "    for dname in dist_order:\n",
    "        if n in instances and dname in instances[n]:\n",
    "            all_cap_ratios_for_n.update(instances[n][dname].keys())\n",
    "    \n",
    "    for cap_name in sorted(list(all_cap_ratios_for_n)):\n",
    "        plot_tasks.append((n, cap_name))\n",
    "\n",
    "# --- Loop over tasks with tqdm progress bar ---\n",
    "if plot_tasks:\n",
    "    print(f\"Generating {len(plot_tasks)} summary visualization plots...\")\n",
    "    \n",
    "    for n, cap_name in tqdm(plot_tasks, desc=\"Generating Viz Summaries\"):\n",
    "        \n",
    "        # --- Build the 'dist_map' for this specific n and cap_name ---\n",
    "        dist_map = {}\n",
    "        for dname in dist_order:\n",
    "            inst = instances[n].get(dname, {}).get(cap_name)\n",
    "            if inst:\n",
    "                dist_map[dname] = inst\n",
    "        \n",
    "        if not dist_map:\n",
    "            # Skip if no data for this combo\n",
    "            continue \n",
    "        # -------------------------------------------------------------------------\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10), tight_layout=True)\n",
    "        \n",
    "        # scatter subplot (weight vs value), overlay distributions\n",
    "        ax_scatter = axes[0,0]\n",
    "        for dname, inst in dist_map.items():\n",
    "            w = np.array([it[\"weight\"] for it in inst[\"items\"]])\n",
    "            v = np.array([it[\"value\"]  for it in inst[\"items\"]])\n",
    "            # sample if too many points\n",
    "            if len(w) > 5000:\n",
    "                idx = np.random.choice(len(w), size=5000, replace=False)\n",
    "                ax_scatter.scatter(w[idx], v[idx], s=6, alpha=0.5, label=dname, color=colors.get(dname))\n",
    "            else:\n",
    "                ax_scatter.scatter(w, v, s=8, alpha=0.6, label=dname, color=colors.get(dname))\n",
    "        ax_scatter.set_xlabel(\"weight\")\n",
    "        ax_scatter.set_ylabel(\"value\")\n",
    "        ax_scatter.set_title(f\"Weight vs Value\")\n",
    "        ax_scatter.legend()\n",
    "        ax_scatter.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # ratio histogram (value/weight)\n",
    "        ax_ratio = axes[0,1]\n",
    "        for dname, inst in dist_map.items():\n",
    "            # Added check for weight > 0 to avoid ZeroDivisionError\n",
    "            ratio = np.array([it[\"value\"]/it[\"weight\"] for it in inst[\"items\"] if it[\"weight\"] > 0], dtype=float)\n",
    "            ax_ratio.hist(ratio, bins=40, alpha=0.6, label=dname, color=colors.get(dname), density=True)\n",
    "        ax_ratio.set_xlabel(\"value / weight\")\n",
    "        ax_ratio.set_ylabel(\"Density\")\n",
    "        ax_ratio.set_title(\"Value / Weight Ratio (Density)\")\n",
    "        ax_ratio.legend()\n",
    "\n",
    "        # ECDF for weights\n",
    "        ax_ecdf = axes[1,0]\n",
    "        for dname, inst in dist_map.items():\n",
    "            w = [it[\"weight\"] for it in inst[\"items\"]]\n",
    "            x, y = ecdf(w)\n",
    "            ax_ecdf.plot(x, y, label=dname, color=colors.get(dname))\n",
    "        ax_ecdf.set_xlabel(\"weight\")\n",
    "        ax_ecdf.set_ylabel(\"ECDF (Cumulative Probability)\")\n",
    "        ax_ecdf.set_title(\"ECDF of weights\")\n",
    "        ax_ecdf.legend()\n",
    "        ax_ecdf.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Boxplot comparing weight distributions\n",
    "        ax_box = axes[1,1]\n",
    "        labels = []\n",
    "        data = []\n",
    "        # Use dist_order to ensure consistent boxplot order\n",
    "        for dname in dist_order:\n",
    "            if dname in dist_map:\n",
    "                labels.append(dname)\n",
    "                data.append([it[\"weight\"] for it in dist_map[dname][\"items\"]])\n",
    "        \n",
    "        if data:\n",
    "            ax_box.boxplot(data, tick_labels=labels, showfliers=False)\n",
    "        ax_box.set_ylabel(\"weight\")\n",
    "        ax_box.set_title(\"Boxplot — weights by distribution\")\n",
    "\n",
    "        # --- Updated title ---\n",
    "        fig.suptitle(f\"Knapsack Visual Summary — n={n}, {cap_name}\", fontsize=16)\n",
    "        \n",
    "        if SAVE:\n",
    "            # --- MODIFICATION: Save path now uses SUMMARIES_DIR ---\n",
    "            out_path = SUMMARIES_DIR / f\"viz_summary_n{n}_{cap_name}.png\"\n",
    "            fig.savefig(out_path, bbox_inches=\"tight\", dpi=150)\n",
    "            # print(\"Saved:\", out_path) # Removed print for cleaner tqdm output\n",
    "        \n",
    "        # --- Removed plt.show() ---\n",
    "        plt.close(fig)\n",
    "\n",
    "    # --- MODIFICATION: Updated final print statement ---\n",
    "    print(f\"\\nAll summary visualizations saved to {SUMMARIES_DIR}\")\n",
    "else:\n",
    "    print(\"No instances found to visualize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4c59859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating 9 Zipf CCDF plots and numeric summaries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing Instances: 100%|██████████| 9/9 [00:01<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric summary successfully saved to: knapsack_multisize_data\\numeric_summary.csv\n",
      "Zipf CCDF plots saved to: knapsack_multisize_data\\plots\\zipf_ccdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# (Assuming imports like plt, np, Path, SIZES, OUT_ROOT, stats, 'instances', and 'dist_order' are loaded)\n",
    "import csv  # <-- Import CSV module\n",
    "from tqdm import tqdm # <-- Import tqdm\n",
    "\n",
    "# --- MODIFICATION: Define root plot dir and specific subdir ---\n",
    "PLOTS_ROOT = OUT_ROOT / \"plots\"  # Assuming OUT_ROOT is defined\n",
    "ZIPF_PLOTS_DIR = PLOTS_ROOT / \"zipf_ccdf\" # <-- New subdirectory name\n",
    "PLOTS_ROOT.mkdir(exist_ok=True)\n",
    "ZIPF_PLOTS_DIR.mkdir(exist_ok=True) # <-- Create the new subdirectory\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# --- Create a flat list of all tasks ---\n",
    "# (This logic is unchanged)\n",
    "plot_tasks = []\n",
    "for n in sorted(instances.keys()):\n",
    "    all_cap_ratios_for_n = set()\n",
    "    for dname in dist_order: # dist_order = [\"uniform\", \"normal\", \"zipf\"]\n",
    "        if n in instances and dname in instances[n]:\n",
    "            all_cap_ratios_for_n.update(instances[n][dname].keys())\n",
    "    \n",
    "    for cap_name in sorted(list(all_cap_ratios_for_n)):\n",
    "        plot_tasks.append((n, cap_name))\n",
    "\n",
    "# --- List to store summary data for CSV ---\n",
    "summary_data = []\n",
    "csv_header = [\n",
    "    \"n\", \"distribution\", \"capacity_ratio\", \n",
    "    \"mean_weight\", \"std_weight\", \"mean_value\", \"std_value\", \n",
    "    \"pearson_r\", \"p_value\"\n",
    "]\n",
    "\n",
    "print(f\"\\nGenerating {len(plot_tasks)} Zipf CCDF plots and numeric summaries...\")\n",
    "\n",
    "# --- Loop over tasks with tqdm ---\n",
    "for n, cap_name in tqdm(plot_tasks, desc=\"Summarizing Instances\"):\n",
    "\n",
    "    # --- 1. Zipf log-log CCDF plot ---\n",
    "    # Check if a 'zipf' instance exists for this (n, cap_name)\n",
    "    inst_zipf = instances[n].get(\"zipf\", {}).get(cap_name)\n",
    "    \n",
    "    if inst_zipf:\n",
    "        w = np.array([it[\"weight\"] for it in inst_zipf[\"items\"]])\n",
    "        x, y = ccdf(w) # ccdf helper function must be defined\n",
    "        mask = (x > 0) & (y > 0)\n",
    "        x_m, y_m = x[mask], y[mask]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        ax.loglog(x_m, y_m, marker='.', markersize=4, linestyle='none')\n",
    "        ax.set_xlabel(\"weight (log)\")\n",
    "        ax.set_ylabel(\"CCDF (log)\")\n",
    "        ax.set_title(f\"Zipf — CCDF (log-log) n={n}, {cap_name}\")\n",
    "        ax.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "        \n",
    "        # --- MODIFICATION: Save path now uses ZIPF_PLOTS_DIR ---\n",
    "        out_path = ZIPF_PLOTS_DIR / f\"zipf_ccdf_n{n}_{cap_name}.png\"\n",
    "        fig.savefig(out_path, bbox_inches=\"tight\", dpi=150)\n",
    "        \n",
    "        # plt.show() # <-- Removed\n",
    "        plt.close(fig) # <-- Close figure to free memory\n",
    "\n",
    "    # --- 2. Numeric summary & correlation ---\n",
    "    # (This logic is unchanged)\n",
    "    \n",
    "    for dname in dist_order:\n",
    "        inst = instances[n].get(dname, {}).get(cap_name)\n",
    "        if not inst:\n",
    "            continue\n",
    "            \n",
    "        w = np.array([it[\"weight\"] for it in inst[\"items\"]])\n",
    "        v = np.array([it[\"value\"]  for it in inst[\"items\"]])\n",
    "        \n",
    "        mean_w, std_w = (w.mean(), w.std(ddof=0)) if len(w) > 0 else (0, 0)\n",
    "        mean_v, std_v = (v.mean(), v.std(ddof=0)) if len(v) > 0 else (0, 0)\n",
    "        \n",
    "        # Pearson correlation (safe)\n",
    "        r, p = (float('nan'), float('nan'))\n",
    "        if len(w) > 1 and len(v) > 1 and std_w > 0 and std_v > 0:\n",
    "            try:\n",
    "                r, p = stats.pearsonr(w, v)\n",
    "            except Exception:\n",
    "                pass # Keep default nan\n",
    "        \n",
    "        # Optional: print to console\n",
    "        # print(f\" {dname:7s} | mean_w={mean_w:6.1f} std_w={std_w:6.1f} | mean_v={mean_v:7.1f} std_v={std_v:6.1f} | pearson_r={r:6.3f} (p={p:.2g})\")\n",
    "        \n",
    "        # Append data for CSV\n",
    "        summary_data.append({\n",
    "            \"n\": n,\n",
    "            \"distribution\": dname,\n",
    "            \"capacity_ratio\": cap_name,\n",
    "            \"mean_weight\": round(mean_w, 2),\n",
    "            \"std_weight\": round(std_w, 2),\n",
    "            \"mean_value\": round(mean_v, 2),\n",
    "            \"std_value\": round(std_v, 2),\n",
    "            \"pearson_r\": round(r, 5) if not np.isnan(r) else r,\n",
    "            \"p_value\": round(p, 5) if not np.isnan(p) else p\n",
    "        })\n",
    "\n",
    "# --- 3. Write summary data to CSV file ---\n",
    "summary_path = OUT_ROOT / \"numeric_summary.csv\"\n",
    "try:\n",
    "    with open(summary_path, \"w\", newline='', encoding='utf8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=csv_header)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(summary_data)\n",
    "    \n",
    "    print(f\"\\nNumeric summary successfully saved to: {summary_path}\")\n",
    "    # --- MODIFICATION: Updated final print statement ---\n",
    "    print(f\"Zipf CCDF plots saved to: {ZIPF_PLOTS_DIR}\")\n",
    "except IOError as e:\n",
    "    print(f\"\\nError writing summary CSV to {summary_path}: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred during CSV writing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e80bef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============================================================================================================================\n",
      "\n",
      "SUMMARY for n=50\n",
      "\n",
      " Distribution: Uniform\n",
      "  cap_0.2 | seed=  20251020 | capacity= 2516 | mean_w= 251.6 | mean_v= 483.2\n",
      "    sample: (id=0,w=45,v=988), (id=1,w=493,v=11), (id=2,w=441,v=580), (id=3,w=230,v=643), (id=4,w=479,v=620)\n",
      "  cap_0.5 | seed=  20251023 | capacity= 6008 | mean_w= 240.3 | mean_v= 531.0\n",
      "    sample: (id=0,w=65,v=675), (id=1,w=482,v=618), (id=2,w=114,v=330), (id=3,w=191,v=525), (id=4,w=91,v=318)\n",
      "  cap_0.8 | seed=  20251026 | capacity= 9769 | mean_w= 244.2 | mean_v= 455.3\n",
      "    sample: (id=0,w=81,v=811), (id=1,w=222,v=949), (id=2,w=177,v=524), (id=3,w=125,v=549), (id=4,w=37,v=596)\n",
      "----------------------------------------------------------------------\n",
      " Distribution: Normal\n",
      "  cap_0.2 | seed=  20251120 | capacity= 2587 | mean_w= 258.7 | mean_v= 493.7\n",
      "    sample: (id=0,w=217,v=619), (id=1,w=261,v=267), (id=2,w=113,v=170), (id=3,w=185,v=281), (id=4,w=295,v=243)\n",
      "  cap_0.5 | seed=  20251123 | capacity= 6696 | mean_w= 267.9 | mean_v= 488.0\n",
      "    sample: (id=0,w=369,v=160), (id=1,w=227,v=782), (id=2,w=253,v=414), (id=3,w=154,v=414), (id=4,w=351,v=581)\n",
      "  cap_0.8 | seed=  20251126 | capacity=10558 | mean_w= 263.9 | mean_v= 452.0\n",
      "    sample: (id=0,w=206,v=542), (id=1,w=192,v=299), (id=2,w=414,v=465), (id=3,w=252,v=330), (id=4,w=370,v=365)\n",
      "----------------------------------------------------------------------\n",
      " Distribution: Zipf\n",
      "  cap_0.2 | seed=  20251220 | capacity=  178 | mean_w=  17.8 | mean_v=  26.6\n",
      "    sample: (id=0,w=4,v=57), (id=1,w=2,v=2), (id=2,w=2,v=2), (id=3,w=57,v=5), (id=4,w=205,v=3)\n",
      "  cap_0.5 | seed=  20251223 | capacity=  328 | mean_w=  13.1 | mean_v=  19.6\n",
      "    sample: (id=0,w=2,v=5), (id=1,w=2,v=21), (id=2,w=2,v=2), (id=3,w=3,v=4), (id=4,w=10,v=5)\n",
      "  cap_0.8 | seed=  20251226 | capacity=  252 | mean_w=   6.3 | mean_v=  37.0\n",
      "    sample: (id=0,w=3,v=2), (id=1,w=5,v=3), (id=2,w=14,v=2), (id=3,w=4,v=2), (id=4,w=50,v=2)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=============================================================================================================================\n",
      "\n",
      "SUMMARY for n=200\n",
      "\n",
      " Distribution: Uniform\n",
      "  cap_0.2 | seed=  20251021 | capacity=10084 | mean_w= 252.1 | mean_v= 496.9\n",
      "    sample: (id=0,w=150,v=150), (id=1,w=57,v=157), (id=2,w=117,v=965), (id=3,w=372,v=14), (id=4,w=330,v=472)\n",
      "  cap_0.5 | seed=  20251024 | capacity=24390 | mean_w= 243.9 | mean_v= 507.8\n",
      "    sample: (id=0,w=283,v=604), (id=1,w=202,v=738), (id=2,w=124,v=994), (id=3,w=275,v=247), (id=4,w=40,v=47)\n",
      "  cap_0.8 | seed=  20251027 | capacity=41033 | mean_w= 256.5 | mean_v= 485.7\n",
      "    sample: (id=0,w=167,v=449), (id=1,w=299,v=775), (id=2,w=130,v=550), (id=3,w=217,v=916), (id=4,w=438,v=14)\n",
      "----------------------------------------------------------------------\n",
      " Distribution: Normal\n",
      "  cap_0.2 | seed=  20251121 | capacity=10118 | mean_w= 252.9 | mean_v= 481.7\n",
      "    sample: (id=0,w=176,v=554), (id=1,w=151,v=321), (id=2,w=272,v=518), (id=3,w=266,v=504), (id=4,w=289,v=577)\n",
      "  cap_0.5 | seed=  20251124 | capacity=25337 | mean_w= 253.4 | mean_v= 502.2\n",
      "    sample: (id=0,w=321,v=568), (id=1,w=163,v=395), (id=2,w=142,v=804), (id=3,w=236,v=526), (id=4,w=350,v=507)\n",
      "  cap_0.8 | seed=  20251127 | capacity=41377 | mean_w= 258.6 | mean_v= 496.5\n",
      "    sample: (id=0,w=272,v=175), (id=1,w=361,v=766), (id=2,w=225,v=517), (id=3,w=124,v=513), (id=4,w=282,v=540)\n",
      "----------------------------------------------------------------------\n",
      " Distribution: Zipf\n",
      "  cap_0.2 | seed=  20251221 | capacity=  614 | mean_w=  15.4 | mean_v=   8.9\n",
      "    sample: (id=0,w=15,v=2), (id=1,w=3,v=2), (id=2,w=45,v=6), (id=3,w=10,v=2), (id=4,w=19,v=2)\n",
      "  cap_0.5 | seed=  20251224 | capacity= 1112 | mean_w=  11.1 | mean_v=  15.4\n",
      "    sample: (id=0,w=2,v=2), (id=1,w=2,v=6), (id=2,w=2,v=7), (id=3,w=4,v=2), (id=4,w=2,v=101)\n",
      "  cap_0.8 | seed=  20251227 | capacity= 1946 | mean_w=  12.2 | mean_v=   7.0\n",
      "    sample: (id=0,w=2,v=4), (id=1,w=72,v=3), (id=2,w=2,v=2), (id=3,w=2,v=2), (id=4,w=5,v=2)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=============================================================================================================================\n",
      "\n",
      "SUMMARY for n=500\n",
      "\n",
      " Distribution: Uniform\n",
      "  cap_0.2 | seed=  20251022 | capacity=26023 | mean_w= 260.2 | mean_v= 480.6\n",
      "    sample: (id=0,w=470,v=884), (id=1,w=252,v=405), (id=2,w=362,v=705), (id=3,w=449,v=544), (id=4,w=442,v=138)\n",
      "  cap_0.5 | seed=  20251025 | capacity=60982 | mean_w= 243.9 | mean_v= 505.9\n",
      "    sample: (id=0,w=148,v=621), (id=1,w=352,v=761), (id=2,w=197,v=370), (id=3,w=490,v=226), (id=4,w=382,v=531)\n",
      "  cap_0.8 | seed=  20251028 | capacity=101463 | mean_w= 253.7 | mean_v= 493.1\n",
      "    sample: (id=0,w=32,v=553), (id=1,w=152,v=281), (id=2,w=122,v=701), (id=3,w=337,v=947), (id=4,w=147,v=175)\n",
      "----------------------------------------------------------------------\n",
      " Distribution: Normal\n",
      "  cap_0.2 | seed=  20251122 | capacity=24749 | mean_w= 247.5 | mean_v= 509.1\n",
      "    sample: (id=0,w=404,v=558), (id=1,w=313,v=587), (id=2,w=230,v=714), (id=3,w=185,v=581), (id=4,w=207,v=600)\n",
      "  cap_0.5 | seed=  20251125 | capacity=61848 | mean_w= 247.4 | mean_v= 497.0\n",
      "    sample: (id=0,w=314,v=609), (id=1,w=185,v=466), (id=2,w=252,v=782), (id=3,w=233,v=404), (id=4,w=199,v=550)\n",
      "  cap_0.8 | seed=  20251128 | capacity=100698 | mean_w= 251.7 | mean_v= 495.4\n",
      "    sample: (id=0,w=278,v=472), (id=1,w=171,v=414), (id=2,w=316,v=748), (id=3,w=173,v=549), (id=4,w=296,v=351)\n",
      "----------------------------------------------------------------------\n",
      " Distribution: Zipf\n",
      "  cap_0.2 | seed=  20251222 | capacity= 1194 | mean_w=  11.9 | mean_v=  15.1\n",
      "    sample: (id=0,w=3,v=5), (id=1,w=2,v=3), (id=2,w=107,v=7), (id=3,w=10,v=7), (id=4,w=4,v=6)\n",
      "  cap_0.5 | seed=  20251225 | capacity= 3116 | mean_w=  12.5 | mean_v=  14.7\n",
      "    sample: (id=0,w=18,v=9), (id=1,w=4,v=3), (id=2,w=4,v=3), (id=3,w=6,v=3), (id=4,w=125,v=15)\n",
      "  cap_0.8 | seed=  20251228 | capacity= 5883 | mean_w=  14.7 | mean_v=  14.9\n",
      "    sample: (id=0,w=92,v=2), (id=1,w=6,v=2), (id=2,w=2,v=2), (id=3,w=3,v=5), (id=4,w=5,v=3)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# (Assuming SIZES, instances, and dist_order are defined)\n",
    "# dist_order = [\"uniform\", \"normal\", \"zipf\"] # (In case it's not defined)\n",
    "\n",
    "# Print small sample items for manual inspection\n",
    "SAMPLE_K = 5\n",
    "for n in SIZES:\n",
    "    print(\"\\n\" + \"=\"*125)\n",
    "    print(f\"\\nSUMMARY for n={n}\\n\")\n",
    "    \n",
    "    # Loop 1: Distribution (e.g., uniform, normal, zipf)\n",
    "    for dname in dist_order:\n",
    "        \n",
    "        # Get the dictionary of capacity ratios for this distribution\n",
    "        # e.g., {'cap_0.2': {...}, 'cap_0.5': {...}}\n",
    "        cap_map = instances[n].get(dname)\n",
    "        \n",
    "        if not cap_map:\n",
    "            print(f\" Distribution: {dname.capitalize()} (missing)\")\n",
    "            print(\"-\" * 70)\n",
    "            continue\n",
    "            \n",
    "        print(f\" Distribution: {dname.capitalize()}\")\n",
    "        \n",
    "        # Loop 2: Capacity Ratio (e.g., cap_0.2, cap_0.5, cap_0.8)\n",
    "        # We sort by cap_name to ensure a consistent print order\n",
    "        for cap_name, inst in sorted(cap_map.items()):\n",
    "            if inst is None:\n",
    "                print(f\"  {cap_name:7s} | missing\")\n",
    "                continue\n",
    "            \n",
    "            weights = [it[\"weight\"] for it in inst[\"items\"]]\n",
    "            values  = [it[\"value\"]  for it in inst[\"items\"]]\n",
    "            \n",
    "            # Safety check for empty lists\n",
    "            mean_w_str = \"N/A\"\n",
    "            mean_v_str = \"N/A\"\n",
    "            if len(weights) > 0:\n",
    "                mean_w = sum(weights) / len(weights)\n",
    "                mean_v = sum(values) / len(values)\n",
    "                mean_w_str = f\"{mean_w:6.1f}\"\n",
    "                mean_v_str = f\"{mean_v:6.1f}\"\n",
    "\n",
    "            # Updated print statement includes cap_name\n",
    "            print(f\"  {cap_name:7s} | seed={inst['meta']['seed']:10d} | capacity={inst['capacity']:5d} | mean_w={mean_w_str} | mean_v={mean_v_str}\")\n",
    "            \n",
    "            sample = inst[\"items\"][:SAMPLE_K]\n",
    "            sstr = \", \".join([f\"(id={it['id']},w={it['weight']},v={it['value']})\" for it in sample])\n",
    "            print(f\"    sample: {sstr}\")\n",
    "        \n",
    "        print(\"-\" * 70) # Add a separator between distributions\n",
    "\n",
    "print(\"\\n\" + \"=\"*125)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
